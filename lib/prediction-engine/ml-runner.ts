
import * as ort from 'onnxruntime-node';
import path from 'path';
import fs from 'fs';

// Load route map
const ROUTE_MAP_PATH = path.join(process.cwd(), 'lib/prediction-engine/route_map.json');
const ROUTE_MAP: Record<string, number> = JSON.parse(fs.readFileSync(ROUTE_MAP_PATH, 'utf-8'));

// Models (Lazy loaded Singleton)
let sessionClassifier: ort.InferenceSession | null = null;
let sessionRegressor: ort.InferenceSession | null = null;

const MODEL_DIR = path.join(process.cwd(), 'lib/prediction-engine');

async function getSessions() {
    if (!sessionClassifier) {
        sessionClassifier = await ort.InferenceSession.create(path.join(MODEL_DIR, 'status_classifier.onnx'));
    }
    if (!sessionRegressor) {
        sessionRegressor = await ort.InferenceSession.create(path.join(MODEL_DIR, 'recovery_regressor.onnx'));
    }
    return { sessionClassifier, sessionRegressor };
}

export interface MLInput {
    routeId: string;
    month: number;
    windSpeed: number;
    windDirection: number;
    windGust: number;
    snowfall: number;
    snowDepth: number;
    temperature: number;
    pressure: number;
    windChange: number; // ðŸ†•
    pressureChange: number; // ðŸ†•
}

export interface MLOutput {
    status: 'normal' | 'delayed' | 'suspended';
    recoveryTime: number | null; // Hours
    probabilities: {
        normal: number;
        delayed: number;
        suspended: number;
    };
}

export async function predictWithML(input: MLInput): Promise<MLOutput> {
    const { sessionClassifier, sessionRegressor } = await getSessions();

    // Encode Features
    // [route_code, month, wind_speed, wind_dir, wind_gust, snowfall, snow_depth, temperature, pressure, wind_change, pressure_change]
    const routeCode = ROUTE_MAP[input.routeId] ?? -1;
    const safeRouteCode = routeCode === -1 ? 0 : routeCode;

    const features = Float32Array.from([
        safeRouteCode,
        input.month,
        input.windSpeed,
        input.windDirection,
        input.windGust,
        input.snowfall,
        input.snowDepth,
        input.temperature,
        input.pressure,
        input.windChange, // ðŸ†•
        input.pressureChange // ðŸ†•
    ]);

    // Create Tensor (Shape [1, 11])
    const tensor = new ort.Tensor('float32', features, [1, 11]);
    const feeds = { 'float_input': tensor };

    // Run Classifier
    // Output 0: label (int64), Output 1: probabilities (sequence<map>)
    const resultsClf = await sessionClassifier.run(feeds);
    const labelTensor = resultsClf[sessionClassifier.outputNames[0]];
    const labelIdx = Number(labelTensor.data[0]); // 0=normal, 1=delayed, 2=suspended

    // Extract probabilities
    // ONNX Runtime JS 'zipmap' output is complex. 
    // GradientBoostingClassifier output in ONNX usually gives a Map.
    // Let's trust the label for now. Getting probs is tricky in onnxruntime-node depending on specific export options.
    // Actually, Scikit-Learn ONNX usually outputs [label, probabilities_tensor].

    const statusMap = ['normal', 'delayed', 'suspended'];
    const status = statusMap[labelIdx] as MLOutput['status'];

    // Run Regressor
    const resultsReg = await sessionRegressor.run(feeds);
    // Output name usually "variable"
    const regOutputName = sessionRegressor.outputNames[0];
    const recoveryTime = Number(resultsReg[regOutputName].data[0]);

    // Probabilities fallback (dummy for now if complex extraction fails, 
    // but ideally we parse the second output of classifier)
    const probs = { normal: 0, delayed: 0, suspended: 0 };
    // Assuming label 0=normal, 1=delayed, 2=suspended
    probs[status] = 1.0;

    // Correct recovery time: If status is normal, recovery should be 0 (or close to).
    // Model was trained on valid recovery times, so it might predict small noise for normal.
    // Force 0 if normal.
    const finalRecoveryTime = status === 'normal' ? 0 : Math.max(0, recoveryTime);

    return {
        status,
        recoveryTime: finalRecoveryTime,
        probabilities: probs
    };
}
