import { createClient } from '@supabase/supabase-js';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';

// Load environment variables
dotenv.config({ path: path.join(process.cwd(), '.env.local') });

// Supabase Setup
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

if (!supabaseUrl || !supabaseKey) {
    console.error('âŒ Missing Supabase credentials in .env.local');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

import { ROUTE_DEFINITIONS, JR_JSON_URLS as AREAS } from '../lib/jr-status';

const EXCLUDE_KEYWORDS = [
    "é¹¿",
    "äººèº«",
    "ä¿¡å·",
    "è»Šä¸¡",
    "ç·šè·¯æ”¯éšœ",
    "å€’æœ¨",
    "ç‚¹æ¤œ",
    "å·¥äº‹"
];

async function fetchAreaStatus(area: typeof AREAS[0]) {
    console.log(`ğŸ“¡ Fetching ${area.name}...`);
    try {
        const response = await fetch(area.url);
        if (!response.ok) throw new Error(`HTTP ${response.status}`);

        // Handle BOM
        const text = await response.text();
        const json = JSON.parse(text.replace(/^\uFEFF/, ''));

        // 1. Log Raw JSON
        const { data: logData, error: logError } = await supabase
            .from('crawler_logs')
            .insert({
                area_id: area.id,
                raw_json: json,
                status: 'success'
            })
            .select()
            .single();

        if (logError) {
            console.error(`âŒ Failed to log raw JSON for ${area.name}:`, logError);
            return;
        }

        const gaikyoList = json.today?.gaikyo || [];

        for (const item of gaikyoList) {
            const text = (item.honbun || '') + (item.title || '');
            if (!text) continue;

            if (EXCLUDE_KEYWORDS.some(kw => text.includes(kw))) {
                console.log(`âš ï¸ Scaling excluded case: ${text.substring(0, 30)}...`);
                continue;
            }

            const matchedRouteIds: string[] = [];
            for (const def of ROUTE_DEFINITIONS) {
                if (def.validAreas && !def.validAreas.includes(area.id)) continue;
                if (def.keywords.some(kw => text.includes(kw))) {
                    matchedRouteIds.push(def.routeId);
                }
            }

            if (matchedRouteIds.length > 0) {
                // ğŸ†• ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ<BR>ã‚¿ã‚°ã®é™¤å»ï¼‰
                const sanitizedDetails = text.replace(/<BR>/gi, '\n').trim();

                let status = 'normal';
                if (text.includes('é‹ä¼‘') || text.includes('è¦‹åˆ')) status = 'suspended';
                else if (text.includes('é…ã‚Œ') || text.includes('é…å»¶')) status = 'delayed';

                // ğŸ†• ã€Œå†é–‹ã€ã‚’å«ã‚“ã§ã„ã¦ã‚‚ã€ã€Œè¦‹è¾¼ã¿ã€ã‚„ã€Œäºˆå®šã€ã®å ´åˆã¯ 'suspended' ã‚’ç¶­æŒã™ã‚‹
                const isOnlyEstimation = (text.includes('å†é–‹') || text.includes('å¹³å¸¸')) &&
                    (text.includes('è¦‹è¾¼ã¿') || text.includes('äºˆå®š') || text.includes('è¨ˆç”»'));

                if (!isOnlyEstimation && (text.includes('å†é–‹') || text.includes('å¹³å¸¸'))) {
                    status = 'normal';
                }

                let cause = 'weather';
                if (text.includes('é›ª')) cause = 'snow';
                else if (text.includes('é¢¨')) cause = 'wind';
                else if (text.includes('é›¨')) cause = 'rain';

                const date = new Date().toISOString().split('T')[0];
                const time = new Date().toLocaleTimeString('en-US', { hour12: false });

                for (const routeId of matchedRouteIds) {
                    const { error: insertError } = await supabase
                        .from('route_status_history')
                        .insert({
                            date: date,
                            time: time,
                            route_id: routeId,
                            status: status,
                            cause: cause,
                            details: sanitizedDetails,
                            crawler_log_id: logData.id
                        });

                    if (insertError) console.error(`Failed to insert status for ${routeId}:`, insertError);
                    else console.log(`âœ… Saved: [${routeId}] ${status} (${cause})`);
                }
            }
        }

    } catch (e) {
        console.error(`âŒ Error fetching ${area.name}:`, e);
        // Try to log error if table exists, otherwise just console log
        try {
            await supabase.from('crawler_logs').insert({
                area_id: area.id,
                raw_json: {},
                status: 'error',
                error_message: String(e)
            });
        } catch (dbError) {
            console.error('Failed to log error to DB:', dbError);
        }
    }
}

async function main() {
    console.log('ğŸš€ Starting JR Hokkaido Crawler...');
    await Promise.all(AREAS.map(area => fetchAreaStatus(area)));
    console.log('ğŸ Crawler finished.');
}

main();
